<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Face Replacement</title>
  <style>
    canvas {
      border: 2px solid black;
      display: block;
      margin: auto;
    }
  </style>
</head>
<body>

  <!-- ✅ Webcam and canvas must exist before script runs -->
  <video id="webcam" autoplay muted playsinline style="display: none;"></video>
  <canvas id="output"></canvas>

  <script type="module">
    import { FaceLandmarker, FilesetResolver } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3';

    let faceLandmarker;
    let runningMode = 'VIDEO';
    const overlayImage = new Image();
    overlayImage.src = 'face.jpg'; // ✅ Your custom image

    async function init() {
      const vision = await FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm'
      );

      faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
          delegate: 'GPU',
        },
        runningMode,
        numFaces: 1,
      });

      startCamera();
    }

    async function startCamera() {
      const video = document.getElementById("webcam"); // ✅ Now guaranteed to exist
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.play();
      video.onloadeddata = () => detectLoop(video);
    }

    async function detectLoop(video) {
      const canvas = document.getElementById("output");
      const ctx = canvas.getContext("2d");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      async function frameLoop() {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        const results = await faceLandmarker.detectForVideo(video, Date.now());

        if (results.faceLandmarks.length > 0 && overlayImage.complete) {
          const landmarks = results.faceLandmarks[0];
          const nose = landmarks[1];
          const leftEye = landmarks[33];
          const rightEye = landmarks[263];

          const faceCenterX = nose.x * canvas.width;
          const faceCenterY = nose.y * canvas.height;
          const eyeDist = Math.abs((rightEye.x - leftEye.x) * canvas.width);
          const faceWidth = eyeDist * 2;
          const faceHeight = faceWidth * 1.2;

          ctx.drawImage(
            overlayImage,
            faceCenterX - faceWidth / 2,
            faceCenterY - faceHeight / 2,
            faceWidth,
            faceHeight
          );
        }

        requestAnimationFrame(frameLoop);
      }

      frameLoop();
    }

    window.addEventListener('DOMContentLoaded', init);
  </script>
</body>
</html>
